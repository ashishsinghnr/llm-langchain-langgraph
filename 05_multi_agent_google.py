"""
Sample 5G: Multi-Agent System (Google Gemini)
===============================================
Same as 05_multi_agent.py but uses Google's Gemini model.

Requires:
  - GOOGLE_API_KEY in your .env file

Run with New Relic:
  NEW_RELIC_CONFIG_FILE=newrelic.ini newrelic-admin run-program python 05_multi_agent_google.py
"""

import time
from config import get_google_llm
from langchain_google_genai.chat_models import ChatGoogleGenerativeAIError
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.tools import tool
from langchain_core.output_parsers import StrOutputParser
from langchain.agents import create_agent

import newrelic.agent

llm = get_google_llm(temperature=0)


# ===========================================================================
# Step 1: Define tools for each specialized agent
# ===========================================================================

@tool
def search_knowledge(query: str) -> str:
    """Search an internal knowledge base for information on a topic.
    Returns factual information that can be used for writing."""
    knowledge = {
        "python": (
            "Python is a high-level, interpreted programming language created by "
            "Guido van Rossum in 1991. It emphasizes readability and simplicity. "
            "Key features: dynamic typing, garbage collection, large standard library. "
            "Used in web development, data science, AI/ML, automation, and scripting."
        ),
        "langchain": (
            "LangChain is an open-source framework for building LLM-powered applications. "
            "It provides abstractions for chains, agents, memory, and tool use. "
            "Created by Harrison Chase in 2022. Supports OpenAI, Google, Anthropic, etc. "
            "Key components: prompts, models, chains, agents, memory, retrievers."
        ),
        "agents": (
            "In AI, an agent is an autonomous system that perceives its environment "
            "and takes actions to achieve goals. LLM agents use language models to "
            "reason about which tools to use. The ReAct pattern (Reason + Act) is "
            "the most common: the LLM thinks step-by-step, calls tools, observes "
            "results, and iterates until it has an answer."
        ),
    }
    query_lower = query.lower()
    for key, info in knowledge.items():
        if key in query_lower:
            return info
    return f"No specific knowledge found for '{query}'. Try: python, langchain, or agents."


@tool
def get_statistics(topic: str) -> str:
    """Get usage statistics and numbers about a technology topic."""
    stats = {
        "python": "GitHub: #1 language (2025). 15M+ developers. 500K+ PyPI packages.",
        "langchain": "40K+ GitHub stars. 2000+ integrations. Used by 100K+ developers.",
        "agents": "85% of enterprise AI projects plan to use agents by 2026 (Gartner).",
    }
    topic_lower = topic.lower()
    for key, info in stats.items():
        if key in topic_lower:
            return info
    return "No statistics available for this topic."


@tool
def format_as_blog(title: str, content: str) -> str:
    """Format content as a structured blog post with title, bullet points, and sections."""
    lines = content.split(". ")
    body = ""
    for i, line in enumerate(lines):
        line = line.strip().rstrip(".")
        if not line:
            continue
        if i % 3 == 0 and i > 0:
            body += "\n### Key Point\n"
        body += f"- {line}.\n"

    return f"# {title}\n\n{body}\n---\n*Generated by Multi-Agent System*"


# ===========================================================================
# Step 2: Create specialized agents
# ===========================================================================

research_agent = create_agent(
    llm,
    tools=[search_knowledge, get_statistics],
    system_prompt=(
        "You are a research specialist. Your job is to gather comprehensive "
        "information about topics using your tools. Search for knowledge AND "
        "statistics. Return a detailed, factual summary."
    ),
)

writer_agent = create_agent(
    llm,
    tools=[format_as_blog],
    system_prompt=(
        "You are a professional writer. Take the research provided and "
        "create well-structured, engaging content. Use the format_as_blog "
        "tool to produce the final output."
    ),
)


# ===========================================================================
# Step 3: Supervisor coordinates the agents
# ===========================================================================

supervisor_prompt = ChatPromptTemplate.from_messages([
    ("system",
     "You are a project supervisor coordinating a research agent and a "
     "writer agent. Given a user request, decide the plan:\n"
     "1. First, describe what the research agent should investigate\n"
     "2. Then, describe what the writer agent should produce\n"
     "Keep your response as two clear sections: RESEARCH_TASK and WRITER_TASK."),
    ("human", "{input}"),
])

supervisor_chain = supervisor_prompt | llm | StrOutputParser()


def run_multi_agent(question: str):
    """Run the full multi-agent pipeline: Supervisor → Research → Writer."""

    print(f"\n{'=' * 60}")
    print(f"User Request: {question}")
    print("=" * 60)

    print("\n--- SUPERVISOR planning ---")
    plan = supervisor_chain.invoke({"input": question})
    print(plan)

    print("\n--- RESEARCH AGENT working ---")
    research_input = f"Research the following: {question}\n\nSupervisor guidance: {plan}"
    research_result = research_agent.invoke(
        {"messages": [("human", research_input)]}
    )
    research_output = research_result["messages"][-1].content
    print(f"Research output: {research_output[:200]}...")

    print("\n--- WRITER AGENT working ---")
    writer_input = (
        f"Write a blog post about: {question}\n\n"
        f"Research findings:\n{research_output}"
    )
    writer_result = writer_agent.invoke(
        {"messages": [("human", writer_input)]}
    )
    final_output = writer_result["messages"][-1].content

    print(f"\n{'=' * 60}")
    print("FINAL OUTPUT:")
    print("=" * 60)
    print(final_output)


# ===========================================================================
# Step 4: Run examples
# ===========================================================================

def safe_run(question: str):
    for attempt in range(3):
        try:
            run_multi_agent(question)
            return
        except ChatGoogleGenerativeAIError as e:
            wait = 30 * (attempt + 1)
            print(f"  [Error: {e}]")
            print(f"  [Retrying in {wait}s]")
            time.sleep(wait)
    print("  [Skipped — rate limit]")


app = newrelic.agent.register_application(timeout=30)

try:
    with newrelic.agent.BackgroundTask(app, name="multi-agent-google", group="LangChain"):

        safe_run("Write a blog post about what LangChain agents are and why they matter")

finally:
    newrelic.agent.shutdown_agent(timeout=10)
